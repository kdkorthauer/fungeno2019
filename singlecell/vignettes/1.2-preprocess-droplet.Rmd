---
title: Preprocessing and normalization of single-cell RNA-seq droplet data
date: "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    toc: true
    toc_float: true
bibliography: ref.bib
---   

```{r, echo=FALSE, message=FALSE, results="hide", cache=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
set.seed(651)
```

This workflow is adapted from portions of the [simpleSingleCell Bioconductor workflow](https://www.bioconductor.org/help/workflows/simpleSingleCell/) by Aaron Lun, Davis McCarthy, and John Marioni. Some sections have been simplified, additional material has been added exploring additional methods, and exercises have been added.

# Overview 

Droplet-based scRNA-seq protocols capture cells in droplets for massively multiplexed library prepation [@klein2015droplet;@macosko2015highly].
This greatly increases the throughput of scRNA-seq studies, allowing tens of thousands of individual cells to be profiled in a routine experiment.
However, it (again) involves some differences from the previous workflows to reflect some unique aspects of droplet-based data.

Here, we describe a brief analysis of the peripheral blood mononuclear cell (PBMC) dataset from 10X Genomics [@zheng2017massively].
The data are publicly available from the [10X Genomics website](https://support.10xgenomics.com/single-cell-gene-expression/datasets/2.1.0/pbmc4k), 
from which we download the raw gene/barcode count matrices, i.e., before cell calling from the _CellRanger_ pipeline.

```{r}
library(BiocFileCache)
bfc <- BiocFileCache("../raw_data", ask = FALSE)
raw.path <- bfcrpath(bfc, file.path("http://cf.10xgenomics.com/samples",
    "cell-exp/2.1.0/pbmc4k/pbmc4k_raw_gene_bc_matrices.tar.gz"))
untar(raw.path, exdir=file.path("../raw_data/pbmc4k"))
```

# Setting up the data

## Reading in a sparse matrix

We load in the raw count matrix using the `read10xCounts()` function from the `r Biocpkg("DropletUtils")` package.
This will create a `SingleCellExperiment` object where each column corresponds to a cell barcode.

```{r}
library(DropletUtils)
fname <- file.path("../raw_data/pbmc4k/raw_gene_bc_matrices/GRCh38")
sce <- read10xCounts(fname, col.names=TRUE)
sce
```

Here, each count represents the number of unique molecular identifiers (UMIs) assigned to a gene for a cell barcode.
Note that the counts are loaded as a sparse matrix object - specifically, a `dgCMatrix` instance from the `r CRANpkg("Matrix")` package.
This avoids allocating memory to hold zero counts, which is highly memory-efficient for low-coverage scRNA-seq data.

```{r}
class(counts(sce))
```

## Annotating the rows

We relabel the rows with the gene symbols for easier reading.
This is done using the `uniquifyFeatureNames()` function, which ensures uniqueness in the case of duplicated or missing symbols.

```{r}
library(scater)
rownames(sce) <- uniquifyFeatureNames(rowData(sce)$ID, rowData(sce)$Symbol)
head(rownames(sce))
```

We also identify the chromosomal location for each gene.
The mitochondrial location is particularly useful for later quality control.

```{r}
library(EnsDb.Hsapiens.v86)
location <- mapIds(EnsDb.Hsapiens.v86, keys=rowData(sce)$ID, 
    column="SEQNAME", keytype="GENEID")
rowData(sce)$CHR <- location
```

# Calling cells from empty droplets

## Testing for deviations from ambient expression

An interesting aspect of droplet-based data is that we have no prior knowledge about which droplets (i.e., cell barcodes) actually contain cells, and which are empty.
Thus, we need to call cells from empty droplets based on the observed expression profiles.
This is not entirely straightforward as empty droplets can contain ambient (i.e., extracellular) RNA that can be captured and sequenced.
The distribution of total counts exhibits a sharp transition between barcodes with large and small total counts (Figure \@ref(fig:rankplot)),
probably corresponding to cell-containing and empty droplets respectively.

```{r rankplot, fig.cap="Total UMI count for each barcode in the PBMC dataset, plotted against its rank (in decreasing order of total counts). The inferred locations of the inflection and knee points are also shown."}
bcrank <- barcodeRanks(counts(sce))

# Only showing unique points for plotting speed.
uniq <- !duplicated(bcrank$rank)
plot(bcrank$rank[uniq], bcrank$total[uniq], log="xy",
    xlab="Rank", ylab="Total UMI count", cex.lab=1.2)

abline(h=metadata(bcrank)$inflection, col="darkgreen", lty=2)
abline(h=metadata(bcrank)$knee, col="dodgerblue", lty=2)

legend("bottomleft", legend=c("Inflection", "Knee"), 
	col=c("darkgreen", "dodgerblue"), lty=2, cex=1.2)
```

We use the `emptyDrops()` function to test whether the expression profile for each cell barcode is significantly different from the ambient RNA pool [@lun2018distinguishing].
Any significant deviation indicates that the barcode corresponds to a cell-containing droplet.
We call cells at a false discovery rate (FDR) of 0.1%, meaning that no more than 0.1% of our called barcodes should be empty droplets on average.

```{r}
set.seed(100)
e.out <- emptyDrops(counts(sce))
sum(e.out$FDR <= 0.001, na.rm=TRUE)
```

We then subset our `SingleCellExperiment` object to retain only the detected cells.

```{r}
# using which() to automatically remove NAs.
sce <- sce[,which(e.out$FDR <= 0.001)]
```

## Examining cell-calling diagnostics

As mentioned above, `emptyDrops()` assumes that barcodes with very low total UMI counts are empty droplets.
Thus, the null hypothesis should be true for all of these barcodes. 
We can check whether the hypothesis test holds its size by examining the distribution of $p$-values for low-total barcodes.
Ideally, the distribution should be close to uniform.

```{r ambientpvalhist, fig.cap="Distribution of $p$-values for the assumed empty droplets."}
full.data <- read10xCounts(fname, col.names=TRUE)
set.seed(100)
limit <- 100   
all.out <- emptyDrops(counts(full.data), lower=limit, test.ambient=TRUE)
hist(all.out$PValue[all.out$Total <= limit & all.out$Total > 0],
    xlab="P-value", main="", col="grey80") 
```

Large peaks near zero indicate that barcodes with total counts below `lower` are not all ambient in origin.
This can be resolved by decreasing `lower` further to exclude barcodes corresponding to droplets with very small cells.

# Quality control on the cells

The previous step only distinguishes cells from empty droplets, but makes no statement about the quality of the cells.
It is entirely possible for droplets to contain damaged or dying cells, which need to be removed prior to downstream analysis.
We compute some QC metrics using `calculateQCMetrics()` [@mccarthy2017scater] and examine their distributions in Figure \@ref(fig:qchist).

```{r qchist, fig.width=10, fig.height=4, fig.cap="Histograms of QC metric distributions in the PBMC dataset."}
sce <- calculateQCMetrics(sce, feature_controls=list(Mito=which(location=="MT")))
par(mfrow=c(1,3))
hist(sce$log10_total_counts, breaks=20, col="grey80",
    xlab="Log-total UMI count")
hist(sce$log10_total_features_by_counts, breaks=20, col="grey80",
    xlab="Log-total number of expressed features")
hist(sce$pct_counts_Mito, breaks=20, col="grey80",
	xlab="Proportion of reads in mitochondrial genes")
```

Ideally, we would remove cells with low library sizes or total number of expressed features.
However, this would likely remove cell types with low RNA content, especially in a heterogeneous PBMC population with many different cell types.
Thus, we use a more relaxed strategy and only remove cells with large mitochondrial proportions, using it as a proxy for cell damage.
(Keep in mind that droplet-based datasets usually do not have spike-in RNA.)

```{r}
high.mito <- isOutlier(sce$pct_counts_Mito, nmads=3, type="higher")
sce <- sce[,!high.mito]
summary(high.mito)
```

# Examining gene expression

The average expression of each gene is much lower here compared to the previous dataset (Figure \@ref(fig:abhist)).
This is due to the reduced coverage per cell when thousands of cells are multiplexed together for sequencing.

```{r abhist, fig.cap="Histogram of the log~10~-average counts for each gene in the PBMC dataset."}
ave <- calcAverage(sce)
rowData(sce)$AveCount <- ave
hist(log10(ave), col="grey80")
```

The set of most highly expressed genes is dominated by ribosomal protein and mitochondrial genes (Figure \@ref(fig:highexpr)), as expected.

```{r highexpr, fig.wide=TRUE, fig.cap="Percentage of total counts assigned to the top 25 most highly-abundant features in the PBMC dataset. For each feature, each bar represents the percentage assigned to that feature for a single cell, while the circle represents the average across all cells. Bars are coloured by the total number of expressed features in each cell."}
plotHighestExprs(sce, n=25) + theme(text = element_text(size=14))
```

# Normalizing for cell-specific biases

We normalize endogenous genes using the `computeSumFactors()` function with an additional pre-clustering step [@lun2016pooling].
Cells in each cluster are normalized separately, and the size factors are rescaled to be comparable across clusters.
This avoids the need to assume that most genes are non-DE across the entire population - only a non-DE majority is required between pairs of clusters.
Scaling is then performed to ensure that size factors of cells in different clusters are comparable.

 We speed up clustering by performing fast dimensionality reduction and then clustering cells on the PCs.
This is the purpose of the `BSPARAM=` argument, which instructs `quickCluster()` to use a approximate algorithm for PCA^[Using methods from the `r CRANpkg("irlba")` package.].
The approximation relies on stochastic initialization so we need to set the random seed for reproducibility - see below for more detail.

```{r}
library(scran)
library(BiocSingular)
set.seed(1000)
clusters <- quickCluster(sce, BSPARAM=IrlbaParam())
table(clusters)
```

We apply the deconvolution method to compute size factors for all cells [@lun2016pooling].
The specification of `cluster=` also ensures that we do not pool cells that are very different. We use a average count threshold of 0.1 to define high-abundance genes to use during normalization.
This is lower than the default threshold of `min.mean=1`, reflecting the fact that UMI counts are generally smaller than read counts.

```{r}
sce <- computeSumFactors(sce, min.mean=0.1, cluster=clusters)
summary(sizeFactors(sce))
```

The size factors are well correlated against the library sizes (Figure \@ref(fig:sfplot)), indicating that capture efficiency and sequencing depth are the major biases.

```{r sfplot, fig.cap="Size factors for all cells in the PBMC dataset, plotted against the library size."}
plot(sce$total_counts, sizeFactors(sce), log="xy")
```

Finally, we compute normalized log-expression values.
There is no need to call `computeSpikeFactors()` here, as there are no spike-in transcripts available.

```{r}
sce <- normalize(sce)
```

# Modelling the mean-variance trend

The lack of spike-in transcripts complicates the modelling of the technical noise.
One option is to assume that most genes do not exhibit strong biological variation, and to fit a trend to the variances of endogenous genes
(see `r simpleSingleCell:::.link("var", "When spike-ins are unavailable", "here")` for details).
However, this assumption is generally unreasonable for a heterogeneous population.
Instead, we assume that the technical noise is Poisson and create a fitted trend on that basis using the `makeTechTrend()` function. Note that this tends to yield large biological components for highly-expressed genes for which Poisson noise is low (in the log-expression space). This often includes so-called "house-keeping" genes coding for essential cellular components such as ribosomal proteins. Although they can indeed be differentially expressed, their impact in the analaysis can be reduced by fitting the mean-variance trend to the endogenous genes.

```{r}
new.trend <- makeTechTrend(x=sce)
```

We estimate the variances for all genes and compare the trend fits in Figure \@ref(fig:trendplot).
The Poisson-based trend serves as a lower bound for the variances of the endogenous genes.
This results in non-zero biological components for most genes, which is consistent with other UMI-based data sets 
(see the `r simpleSingleCell:::.link("umis", "Modelling and removing technical_noise", "corresponding analysis")` of the @zeisel2015brain data set).

```{r trendplot, fig.cap="Variance of normalized log-expression values for each gene in the PBMC dataset, plotted against the mean log-expression. The blue line represents the mean-dependent trend fitted to the variances, while the red line represents the Poisson noise."}
fit <- trendVar(sce, use.spikes=FALSE, loess.args=list(span=0.05))
plot(fit$mean, fit$var, pch=16)
curve(fit$trend(x), col="dodgerblue", add=TRUE)
curve(new.trend(x), col="red", add=TRUE)
```

We decompose the variance for each gene using the Poisson-based trend, and examine the genes with the highest biological components.

```{r}
fit$trend <- new.trend # overwrite trend.
dec <- decomposeVar(fit=fit) # use per-gene variance estimates in 'fit'.
top.dec <- dec[order(dec$bio, decreasing=TRUE),] 
head(top.dec)
```

We can plot the genes with the largest biological components, to verify that they are indeed highly variable (Figure \@ref(fig:hvgplot)).

```{r hvgplot, fig.wide=TRUE, fig.cap="Distributions of normalized log-expression values for the top 10 genes with the largest biological components in the PBMC dataset. Each point represents the log-expression value in a single cell."}
plotExpression(sce, features=rownames(top.dec)[1:10])
```


We use `denoisePCA()` to choose the number of principal components (PCs) to retain based on the technical noise per gene.
We need to set the seed for reproducibility when `BSPARAM=IrlbaParam()`, due to the use of randomized methods from `r Biocpkg("irlba")`.

```{r}
set.seed(12345)
sce <- denoisePCA(sce, technical=new.trend, BSPARAM=IrlbaParam())
ncol(reducedDim(sce))
```

# Doublet detection with clusters

In single-cell RNA sequencing (scRNA-seq) experiments, doublets are artifactual libraries generated from two cells.
They typically arise due to errors in cell sorting or capture, especially in droplet-based protocols [@zheng2017massively] involving thousands of cells.
Doublets are obviously undesirable when the aim is to characterize populations at the _single_-cell level.
In particular, they can incorrectly suggest the existence of intermediate populations or transitory states that not actually exist.
Thus, it is desirable to remove doublet libraries so that they do not compromise interpretation of the results. 
Note that doublet detection procedures should only be applied to libraries generated in the same experimental batch, since it is obviously impossible for doublets to form between two cells that were captured separately.

Several experimental strategies are available for doublet removal.
One approach exploits natural genetic variation when pooling cells from multiple donor individuals [@kang2018multiplexed].
Doublets can be identified as libraries with allele combinations that do not exist in any single donor.
Another approach is to mark a subset of cells (e.g., all cells from one sample) with an antibody conjugated to a different oligonucleotide [@stoeckius2017hashing].
Upon pooling, libraries that are observed to have different oligonucleotides are considered to be doublets and removed.
These approaches can be highly effective but rely on experimental information that may not be available.

## Clustering into subpopulations

We cluster cells into putative subpopulations using `buildSNNGraph()` [@xu2015identification].
We use a higher `k` to increase connectivity and reduce the granularity of the clustering.

```{r}
snn.gr <- buildSNNGraph(sce, use.dimred="PCA", k=10)
sce$Cluster <- factor(igraph::cluster_walktrap(snn.gr)$membership)
table(sce$Cluster)
```

We visualize the clustering on a _t_-SNE plot [@van2008visualizing].
Figure \@ref(fig:tsneclust) shows that there are a number of well-separated clusters as well as some more inter-related clusters.

```{r tsneclust, fig.cap="t-SNE plot of the PBMC data set. Each point is a cell coloured according to its assigned cluster identity."}
set.seed(1000)
sce <- runTSNE(sce, use_dimred="PCA")
plotTSNE(sce, colour_by="Cluster")
```

## Identify intermediate clusters

The `doubletCluster()` function will identify clusters that have intermediate expression profiles of two other clusters [@bach2017differentiation].
Specifically, it will examine every possible triplet of clusters consisting of a query cluster and its two "parents".
It will then compute a number of statistics:

- The number of genes (`N`) that are differentially expressed in the same direction in the query cluster compared to _both_ of the parent clusters.
Such genes would be unique markers for the query cluster and provide evidence against the null hypothesis, i.e., that the query cluster consists of doublets from the two parents.
Clusters with few unique genes are more likely to be doublets.
- The ratio of the median library size in each parent to the median library size in the query (`lib.size*`).
Doublet libraries are generated from a larger initial pool of RNA compared to libraries for single cells, and thus the former should have larger library sizes.
Library size ratios much greater than unity are inconsistent with a doublet identity for the query.
- The proportion of cells in the query cluster should also be reasonable - typically less than 5% of all cells, depending on how many cells were loaded onto the 10X Genomics device.

```{r}
dbl.out <- doubletCluster(sce, sce$Cluster)
dbl.out
```

Examination of the output of `doubletCluster()` indicates that cluster 1 has the fewest unique genes and library sizes that are comparable to or greater than its parents.
We see that every gene detected in this cluster is also expressed in either of the two proposed parent clusters (Figure \@ref(fig:heatclust)).

```{r heatclust, fig.cap="Heatmap of mean-centred and normalized log-expression values for the top set of markers for cluster 1 in the PBMC dataset. Column colours represent the cluster to which each cell is assigned, as indicated by the legend."}
markers <- findMarkers(sce, sce$Cluster, direction="any")
dbl.markers <- markers[["1"]]
chosen <- rownames(dbl.markers)[dbl.markers$Top <= 10]
plotHeatmap(sce, columns=order(sce$Cluster), colour_columns_by="Cluster", 
    features=chosen, cluster_cols=FALSE, center=TRUE, symmetric=TRUE, 
    zlim=c(-3, 4), show_colnames=FALSE)
```

The strength of `doubletCluster()` lies in its simplicity and ease of interpretation.
Suspect clusters can be quickly flagged for further investigation, based on the metrics returned by the function.
However, it is obviously dependent on the quality of the clustering.
Clusters that are too coarse will fail to separate doublets from other cells, while clusters that are too fine will complicate interpretation.

Also note that the output of `doubletClusters()` should be treated as a prioritization of "high-risk" clusters that require more careful investigation - no fixed threshold on any one of the metrics alone is sufficient.

# Doublet detection by simulation

## Background

The other doublet detection strategy involves _in silico_ simulation of doublets from the single-cell expression profiles [@dahlin2018single].
This is performed using the `doubletCells()` function from `r Biocpkg("scran")`, which will:

1. Simulate thousands of doublets by adding together two randomly chosen single-cell profiles.
2. For each original cell, compute the density of simulated doublets in the surrounding neighbourhood.
3. For each original cell, compute the density of other observed cells in the neighbourhood.
4. Return the ratio between the two densities as a "doublet score" for each cell.

This approach assumes that the simulated doublets are good approximations for real doublets.
The use of random selection accounts for the relative abundances of different subpopulations, which affect the likelihood of their involvement in doublets;
and the calculation of a ratio avoids high scores for non-doublet cells in highly abundant subpopulations.
We see the function in action below. Note that to speed up the density calculations, `doubletCells()` will perform a PCA on the log-expression matrix. 
When `BSPARAM=IrlbaParam()`, methods from the `r CRANpkg("irlba")` package are used to perform a fast approximate PCA.
This involves randomization so it is necessary to call `set.seed()` to ensure that results are reproducible.

```{r}
set.seed(100)
dbl.dens <- doubletCells(sce, BSPARAM=IrlbaParam())
summary(dbl.dens)
```

The highest doublet scores are concentrated in a single cluster of cells in the centre of Figure \@ref(fig:denstsne).

```{r denstsne, fig.cap="t-SNE plot of the PBMC data set. Each point is a cell coloured according to its doublet density."}
sce$DoubletScore <- dbl.dens
plotTSNE(sce, colour_by="DoubletScore")
```

From the clustering information, we see that the affected cells belong to the same cluster that was identified using `doubletCluster()` (Figure \@ref(fig:densclust)). 

```{r densclust, fig.cap="Distribution of doublet scores for each cluster in the PBMC data set. Each point is a cell."}
plotColData(sce, x="Cluster", y="DoubletScore", colour_by="Cluster")
```


## Strengths and weaknesses 

The advantage of `doubletCells()` is that it does not depend on clusters, reducing the sensitivity of the results to clustering quality.
The downside is that it requires some strong assumptions about how doublets form, such as the combining proportions and the sampling from pure subpopulations.
In particular, `doubletCells()` treats the library size of each cell as an accurate proxy for its total RNA content.
If this is not true, the simulation will not combine expression profiles from different cells in the correct proportions.
This means that the simulated doublets will be systematically shifted away from the real doublets, resulting in doublet scores that are too low for the latter.

Simply removing cells with high doublet scores will not be sufficient to eliminate real doublets from the data set.
As we can see in Figure \@ref(fig:densclust), only a subset of the cells in the putative doublet cluster actually have high scores.
Removing these would still leave enough cells in that cluster to mislead downstream analyses.
In fact, even defining a threshold on the doublet score is difficult as the interpretation of the score is relative.
There is no general definition for a fixed threshold above which libraries are to be considered doublets.

We recommend interpreting the `doubletCells()` scores in the context of cluster annotation.
All cells from a cluster with a large average doublet score should be considered suspect.
Close neighbours of problematic clusters (e.g., identified by `clusterModularity()`, see `r simpleSingleCell:::.link("umis", "Evaluating graph-based clusters", "here")`) should be treated with caution.
A cluster containing a small proportion of high-scoring cells is generally safe for downstream analyses, provided that the user investigates any interesting results to ensure that they are not being driven by those cells^[For example, checking that DE in an interesting gene is not driven solely by cells with high doublet scores.].
While clustering is still required, this approach is more robust than `doubletClusters()` to the quality of the clustering.

## Remove identified doublet cells

Both approaches above implicated cluster 1 as having a high concentration of doublets. Before proceeding, we'll remove the `r sum(sce$Cluster==1)` cells in this cluster.

```{r}
sce_singlets <- sce[,-which(sce$Cluster==1)]
```

# Save object for later use

Having completed preprocessing and normalization, we save the `SingleCellExperiment` object with its associated data to file.
This avoids having to repeat all of the pre-processing steps described above prior to further analyses.

```{r}
saveRDS(sce_singlets, file="pbmc_postQC.rds")
```

***
# Exercises

For these exercises, use the `SingleCellExperiment` object that hasn't been filtered for doublets (`sce`).

## What proportion of measurements are zero?

```{r}
# your code here

```

## DESeq2 size factors

How many genes can be used in the calcualtion of DESeq2 size factors?  

```{r}
# your code here

```


## Compare empty droplet detection methods

For this exercise, use the full `SingleCellExperiment` object that hasn't been processed for empty droplets.

```{r}
sce.full <- read10xCounts(fname, col.names=TRUE)
```

Call empty drops with the algorithm from the _CellRanger_ pipeline insetad of `emptyDrops()` as used above. The algorithm from _CellRanger_ can be called using the `defaultDrops()` function.

```{r}
# your code here

```

Compare the empty drop calls between the two methods (using FDR 0.001 for emptyDrops) with a 2x2 table.

```{r}
# your code here

```

Plot a histogram of the total counts for the cells called by emptyDrops and not by _CellRanger_, and vise versa. Which tend to have higher total counts?

```{r}
#your code here

```

## Count-depth relationship

Pick a gene with high average expression. Plot the relationship between sequencing depth (size factors) and count of that gene.

```{r}
# your code here

```

## Highly variable genes without transformation

What would be the result of selecting the most highly variable genes without log transformation? Plot the distribution of expression values for the genes with the largest (untransformed) variance.

```{r}
# your code here

```


***

# Session Information

```{r}
sessionInfo()
```

# References
